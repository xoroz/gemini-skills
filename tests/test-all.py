#!/usr/bin/env python3
"""
tests/test-all.py ‚Äî Full end-to-end integration test for Review Site Factory.

Steps:
  1. Server health check
  2. Scrape Google Maps ‚Üí extract first result
  3. POST /generate-site with that data (MODE=DEV ‚Üí cheap images)
  4. Tail build.log live until build completes  [LOCAL only]
  5. Validate output: index.html exists, style.css exists, all 6 images present  [LOCAL only]
  6. Open index.html with Playwright, take a screenshot, check DOM structure  [LOCAL only]

Environment overrides:
  QUERY            ‚Äî Maps search query (default: parrucchiere la spezia)
  BASE_URL         ‚Äî FastAPI base URL (default: http://localhost:8000)
  REMOTE_SITE_URL  ‚Äî Web server base where sites are served (default: derived from host)
                     e.g. http://192.168.0.114  (nginx on port 80 serving /<slug>/index.html)
  WEBHOOK_URL      ‚Äî Webhook for /generate-site (default: dummy)
  BUILD_WAIT       ‚Äî Max seconds to wait for build (default: 900)
  SITES_DIR        ‚Äî Where sites/ folder lives (default: auto-detected from script location)
  REMOTE           ‚Äî Set to "true" / "1" / "yes" to skip local-only steps (default: false)

CLI args (override env vars):
  --remote                  Enable remote mode (skips local filesystem checks)
  --host HOST               Remote host IP / hostname
  --port PORT               FastAPI port (default: 8000)
  --base-url URL            Full FastAPI base URL (overrides --host / --port)
  --remote-url URL          Web server base URL where sites are served
                            (default: http://<host>  i.e. port 80, path /<slug>/index.html)
  --business-type TYPE      Business type for Maps search  (e.g. "parrucchiere")
  --location LOC            Location for Maps search        (e.g. "la spezia")
  --query QUERY             Raw Maps search query (overridden by --business-type + --location)
  --build-wait SECONDS      Max seconds to wait for build (remote: polls site URL)
  --webhook-url URL         Webhook URL passed to /generate-site

Usage examples:
  # Local (default):
  python tests/test-all.py

  # Remote ‚Äî API on :8080, sites served by nginx on :80
  python tests/test-all.py --remote --host 192.168.0.114 --port 8080
  # ‚Üë REMOTE_SITE_URL will default to http://192.168.0.114
  # Site will be validated at http://192.168.0.114/<slug>/index.html

  # Remote with explicit site URL root:
  python tests/test-all.py --remote --host 192.168.0.114 --port 8080 \
      --remote-url http://192.168.0.114/sites

  # Remote via env:
  REMOTE=true BASE_URL=http://192.168.0.114:8080 \
    REMOTE_SITE_URL=http://192.168.0.114 python tests/test-all.py
"""

import argparse
import json
import os
import re
import sys
import time
import urllib.parse
import httpx
from pathlib import Path

# ---------------------------------------------------------------------------
# Load .env if present (optional ‚Äî system env vars always take precedence)
# ---------------------------------------------------------------------------
_env_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), ".env")
if os.path.exists(_env_path):
    with open(_env_path) as _f:
        for _line in _f:
            _line = _line.strip()
            if _line and not _line.startswith("#") and "=" in _line:
                _k, _, _v = _line.partition("=")
                os.environ.setdefault(_k.strip(), _v.strip().strip('"').strip("'"))

# ‚îÄ‚îÄ‚îÄ CLI args ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _parse_args() -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Review Site Factory ‚Äî full integration test",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    parser.add_argument(
        "--remote", action="store_true", default=None,
        help="Remote mode: skip local filesystem steps (build.log, file validation, Playwright file://)",
    )
    parser.add_argument("--host",       metavar="HOST",   help="Remote host IP or hostname")
    parser.add_argument("--port",       metavar="PORT",   help="FastAPI port (default: 8000)")
    parser.add_argument("--base-url",   metavar="URL",    help="Full FastAPI base URL (overrides --host/--port)")
    parser.add_argument("--remote-url", metavar="URL",
        help="Web server base URL where sites are served "
             "(default: http://<host>  ‚Üí  http://<host>/<slug>/index.html)")
    # Search ‚Äî can use structured args OR a raw query string
    parser.add_argument("--business-type", metavar="TYPE",
        help="Business type for Maps search  (e.g. \"parrucchiere\")")
    parser.add_argument("--location",      metavar="LOC",
        help="Location for Maps search  (e.g. \"la spezia\")")
    parser.add_argument("--query",         metavar="QUERY",
        help="Raw Maps search query (overridden by --business-type + --location)")
    parser.add_argument("--build-wait", metavar="SECONDS",type=int, help="Max build wait in seconds")
    parser.add_argument("--webhook-url",metavar="URL",    help="Webhook URL for /generate-site")
    return parser.parse_args()


ARGS = _parse_args()

# ‚îÄ‚îÄ‚îÄ Config (args take precedence over env, env over defaults) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _resolve_bool(args_val, env_key: str, default: bool) -> bool:
    if args_val is not None:
        return bool(args_val)
    env = os.environ.get(env_key, "").lower()
    if env in ("true", "1", "yes"):
        return True
    if env in ("false", "0", "no"):
        return False
    return default

REMOTE = _resolve_bool(ARGS.remote, "REMOTE", False)

def _resolve_base_url() -> str:
    # 1. explicit --base-url
    if ARGS.base_url:
        return ARGS.base_url.rstrip("/")
    # 2. BASE_URL env
    if os.environ.get("BASE_URL"):
        return os.environ["BASE_URL"].rstrip("/")
    # 3. --host / --port combo
    if ARGS.host:
        port = ARGS.port or os.environ.get("PORT", "8000")
        return f"http://{ARGS.host}:{port}"
    # 4. PORT env
    port = os.environ.get("PORT", "8000")
    return f"http://localhost:{port}"

BASE_URL    = _resolve_base_url()
WEBHOOK_URL = ARGS.webhook_url or os.environ.get("WEBHOOK_URL", "https://webhook.site/dummy-test-url")
BUILD_WAIT  = ARGS.build_wait  or int(os.environ.get("BUILD_WAIT", "900"))

# Search query resolution:
#   --business-type + --location  ‚Üí structured (preferred)
#   --query / QUERY env           ‚Üí raw fallback
#   default                       ‚Üí "parrucchiere la spezia"
BUSINESS_TYPE: str = (ARGS.business_type or "").strip()
LOCATION:      str = (ARGS.location      or "").strip()
if BUSINESS_TYPE and LOCATION:
    QUERY = f"{BUSINESS_TYPE} {LOCATION}"          # display / slug purposes
else:
    QUERY = ARGS.query or os.environ.get("QUERY", "parrucchiere la spezia")
    BUSINESS_TYPE = ""
    LOCATION      = ""

API_TOKEN = os.environ.get("API_TOKEN", "")
AUTH_HEADERS = {"Authorization": f"Bearer {API_TOKEN}"} if API_TOKEN else {}
SITE_LANG = os.environ.get("SITE_LANG", "it")

def _resolve_remote_site_url() -> str:
    """
    The web server URL root where generated sites are accessible.
    Separate from BASE_URL (FastAPI) because nginx/apache may serve on a
    different port (usually 80) or path prefix.

    Priority:
      1. --remote-url CLI arg
      2. REMOTE_SITE_URL env var
      3. Derive from --host  ‚Üí  http://<host>   (port 80, no path)
      4. Derive from BASE_URL host, stripping the port  ‚Üí  http://<host>
    """
    if ARGS.remote_url:
        return ARGS.remote_url.rstrip("/")
    if os.environ.get("REMOTE_SITE_URL"):
        return os.environ["REMOTE_SITE_URL"].rstrip("/")
    # Derive from explicit --host
    if ARGS.host:
        return f"http://{ARGS.host}"
    # Derive from BASE_URL by stripping any non-80 port
    import urllib.parse as _up
    parsed = urllib.parse.urlparse(BASE_URL)
    return f"{parsed.scheme}://{parsed.hostname}"

REMOTE_SITE_URL = _resolve_remote_site_url()

# Resolve project root (tests/ lives one level below root)
TESTS_DIR  = Path(__file__).parent.resolve()
PROJECT    = TESTS_DIR.parent
SITES_DIR  = Path(os.environ.get("SITES_DIR", str(PROJECT / "sites")))

# ‚îÄ‚îÄ‚îÄ Colours ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
GREEN  = "\033[0;32m"
RED    = "\033[0;31m"
YELLOW = "\033[1;33m"
CYAN   = "\033[0;36m"
BOLD   = "\033[1m"
DIM    = "\033[2m"
NC     = "\033[0m"

PASS_COUNT = 0
FAIL_COUNT = 0
SKIP_COUNT = 0


def sep():
    print(f"{CYAN}‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ{NC}")


def ok(msg: str):
    global PASS_COUNT
    PASS_COUNT += 1
    print(f"  {GREEN}‚úÖ PASS{NC}: {msg}")


def fail(msg: str, fatal: bool = False):
    global FAIL_COUNT
    FAIL_COUNT += 1
    print(f"  {RED}‚ùå FAIL{NC}: {msg}")
    if fatal:
        summary()
        sys.exit(1)


def skip(msg: str):
    global SKIP_COUNT
    SKIP_COUNT += 1
    print(f"  {YELLOW}‚è≠ SKIP{NC}: {msg}")


def info(msg: str):
    print(f"  {CYAN}‚Ñπ{NC}  {msg}")


def warn(msg: str):
    print(f"  {YELLOW}‚ö†{NC}  {msg}")


def summary():
    sep()
    print()
    status = (
        f"{GREEN}{PASS_COUNT} passed{NC}  |  "
        f"{RED}{FAIL_COUNT} failed{NC}  |  "
        f"{YELLOW}{SKIP_COUNT} skipped{NC}"
    )
    print(f"  {BOLD}Results: {status}{NC}")
    print()


def slug(name: str) -> str:
    """Mirror create.sh slug logic: lowercase, spaces‚Üíhyphens, strip non-alnum-hyphen."""
    s = name.lower().replace(" ", "-")
    s = re.sub(r"[^a-z0-9-]", "", s)
    return s


# ‚îÄ‚îÄ‚îÄ Step 1: Health check ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def step_health():
    print(f"\n{YELLOW}[Step 1] Server health check{NC}")
    try:
        r = httpx.get(f"{BASE_URL}/docs", timeout=5)
        if r.status_code == 200:
            ok(f"Server reachable at {BASE_URL}")
        else:
            fail(f"Server returned HTTP {r.status_code}", fatal=True)
    except Exception as e:
        fail(f"Cannot reach server: {e}", fatal=True)
        print()
        print("  Start it with:")
        print("    source venv/bin/activate && uvicorn main:app --host 0.0.0.0 --port 8000")


# ‚îÄ‚îÄ‚îÄ Step 2: Scrape ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def step_scrape() -> dict:
    print(f"\n{YELLOW}[Step 2] Scrape Google Maps{NC}")

    # Build request: prefer structured business_type + location params
    if BUSINESS_TYPE and LOCATION:
        params = {
            "business_type": BUSINESS_TYPE,
            "location":      LOCATION,
            "max_results":   1,
        }
        info(f'business_type: "{BUSINESS_TYPE}"')
        info(f'location     : "{LOCATION}"')
        # Show the Maps URL that will be constructed server-side
        combined = urllib.parse.quote_plus(f"{BUSINESS_TYPE} {LOCATION}")
        info(f'Maps URL     : https://www.google.com/maps/search/{combined}?hl={SITE_LANG}')
    else:
        params = {
            "query":       QUERY,
            "max_results": 1,
        }
        encoded = urllib.parse.quote_plus(QUERY)
        info(f'query: "{QUERY}"')
        info(f'Maps URL: https://www.google.com/maps/search/{encoded}?hl={SITE_LANG}')

    info("\u23f3 May take up to 30 seconds...")
    print()

    try:
        r = httpx.get(f"{BASE_URL}/scrape-maps", params=params, headers=AUTH_HEADERS, timeout=130)
        data = r.json()
    except Exception as e:
        fail(f"Scrape request failed: {e}", fatal=True)
        return {}

    print("  Response:")
    print("  " + json.dumps(data, indent=2, ensure_ascii=False).replace("\n", "\n  "))
    print()

    if data.get("status") != "success" or not data.get("data"):
        fail("Scrape returned no results", fatal=True)
        return {}

    biz = data["data"][0]
    if not biz.get("business_name"):
        fail("Scrape result has no business_name", fatal=True)
        return {}

    ok(f"Scraped: \"{biz['business_name']}\"")
    info(f"  niche:   {biz.get('niche', '‚Äî')}")
    info(f"  address: {biz.get('address', '‚Äî')}")
    info(f"  tel:     {biz.get('tel', '‚Äî')}")
    return biz


# ‚îÄ‚îÄ‚îÄ Step 3: Trigger build ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def step_generate(biz: dict) -> str:
    """Returns the slug (business name slugified) used as site identifier."""
    name = biz["business_name"]
    print(f"\n{YELLOW}[Step 3] Trigger site build for \"{name}\"{NC}")
    info("MODE=DEV ‚Üí using sourceful/riverflow-v2-fast (cheap/fast images)")
    info("API returns immediately; build runs in background.")
    print()

    payload = {
        "business_name": name,
        "niche":         biz.get("niche", ""),
        "address":       biz.get("address", ""),
        "tel":           biz.get("tel", ""),
        "webhook_url":   WEBHOOK_URL,
    }
    print("  Payload:")
    print("  " + json.dumps(payload, indent=2, ensure_ascii=False).replace("\n", "\n  "))
    print()

    try:
        r = httpx.post(f"{BASE_URL}/generate-site",
                          json=payload, headers=AUTH_HEADERS, timeout=10)
        resp = r.json()
    except Exception as e:
        fail(f"/generate-site request failed: {e}", fatal=True)
        return ""

    print("  Response:")
    print("  " + json.dumps(resp, indent=2).replace("\n", "\n  "))
    print()

    if resp.get("status") == "processing":
        ok("/generate-site accepted the job (status=processing)")
    else:
        fail(f"/generate-site unexpected status: {resp.get('status')}", fatal=True)

    site_slug = slug(name)
    if REMOTE:
        info(f"Remote mode ‚Äî site slug: {site_slug}")
    else:
        site_dir = SITES_DIR / site_slug
        info(f"Expected output: {site_dir}")

    return site_slug


# ‚îÄ‚îÄ‚îÄ Step 4a: LOCAL ‚Äî Tail build log from filesystem ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def step_wait_local(site_slug: str):
    site_dir = SITES_DIR / site_slug
    log_file = site_dir / "build.log"
    print(f"\n{YELLOW}[Step 4] Waiting for build to complete (LOCAL ‚Äî tailing log){NC}")
    info(f"Tailing: {log_file}")
    info(f"Timeout: {BUILD_WAIT}s  (set BUILD_WAIT env to change)")
    print()

    deadline = time.time() + BUILD_WAIT
    last_pos  = 0

    # Wait for log file to appear (create.sh creates the folder first)
    print(f"  {DIM}Waiting for build.log to appear...{NC}", end="", flush=True)
    while not log_file.exists():
        if time.time() > deadline:
            print()
            fail(f"build.log never appeared in {site_dir}", fatal=True)
        time.sleep(2)
        print(".", end="", flush=True)
    print(f"  {GREEN}found{NC}")
    print()

    # Tail the log until we see the final "Open:" line
    DONE_MARKER = "üåê Open:"
    done = False

    while time.time() < deadline:
        with open(log_file, "r", errors="replace") as f:
            f.seek(last_pos)
            chunk = f.read()
            if chunk:
                for line in chunk.splitlines():
                    print(f"  {DIM}{line}{NC}")
                last_pos += len(chunk.encode("utf-8", errors="replace"))
                if DONE_MARKER in chunk:
                    done = True
                    break
        time.sleep(1)

    # Give the OS a moment to flush any final file writes
    time.sleep(1)
    print()
    if done:
        ok("Build completed (üåê Open: marker detected in log)")
    else:
        fail(f"Build did not complete within {BUILD_WAIT}s", fatal=True)

    return SITES_DIR / site_slug


# ‚îÄ‚îÄ‚îÄ Step 4b: REMOTE ‚Äî Poll live site URL every 20s ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def step_wait_remote(site_slug: str):
    """
    Remote build wait: polls REMOTE_SITE_URL/<slug>/index.html every 20s
    until it returns HTTP 200 ‚Äî meaning nginx is serving the finished site.
    No fake /status/ endpoint needed.
    """
    site_url      = f"{REMOTE_SITE_URL}/{site_slug}/index.html"
    poll_interval = 20
    deadline      = time.time() + BUILD_WAIT
    start         = time.time()

    print(f"\n{YELLOW}[Step 4] Waiting for build to complete (REMOTE ‚Äî polling live URL){NC}")
    info(f"Polling : {site_url}")
    info(f"Interval: every {poll_interval}s")
    info(f"Timeout : {BUILD_WAIT}s  (set BUILD_WAIT env to change)")
    print()

    attempt = 0
    while time.time() < deadline:
        attempt += 1
        elapsed   = int(time.time() - start)
        remaining = max(0, int(deadline - time.time()))
        try:
            r = httpx.get(site_url, timeout=10)
            if r.status_code == 200:
                ok(f"Site is live! HTTP 200 after ~{elapsed}s  ‚Üí  {site_url}")
                return
            else:
                print(f"  {DIM}[#{attempt}  {elapsed}s elapsed / {remaining}s left]  "
                      f"HTTP {r.status_code} ‚Äî still building...{NC}")
        except httpx.RequestError:
            print(f"  {DIM}[#{attempt}  {elapsed}s elapsed / {remaining}s left]  "
                  f"connection refused ‚Äî server still building...{NC}")
        except Exception as e:
            print(f"  {DIM}[#{attempt}  {elapsed}s elapsed / {remaining}s left]  "
                  f"error: {e}{NC}")

        # Sleep in 1s ticks so Ctrl-C is always responsive
        for _ in range(poll_interval):
            if time.time() >= deadline:
                break
            time.sleep(1)

    fail(f"Site did not come online within {BUILD_WAIT}s at {site_url}", fatal=True)


# ‚îÄ‚îÄ‚îÄ Step 4.5: Fetch build log & stats ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def _parse_build_stats(log_text: str) -> dict:
    """Parse key metrics out of a raw build.log string."""
    import re as _re
    stats: dict = {}

    m = _re.search(r"Total time:\s+([\d]+m\s+[\d]+s)", log_text)
    if m: stats["total_time"] = m.group(1).strip()

    m = _re.search(r"Mode:\s+(\w+)\s+\(([^)]+)\)", log_text)
    if m: stats["mode"] = f"{m.group(1)} ({m.group(2).strip()})"

    m = _re.search(r"Generated:\s+(\d+)\s*/\s*(\d+)", log_text)
    if m:
        stats["images_generated"] = int(m.group(1))
        stats["images_total"]     = int(m.group(2))

    m = _re.search(r"Failed:\s+(\d+)", log_text)
    if m: stats["images_failed"] = int(m.group(1))

    m = _re.search(r"Total:\s+~?\$?([\d.]+)", log_text)
    if m: stats["estimated_cost_usd"] = float(m.group(1))

    m = _re.search(r"Assets size:\s+(\S+)", log_text)
    if m: stats["assets_size"] = m.group(1).strip()

    m = _re.search(r"Total size:\s+(\S+)", log_text)
    if m: stats["total_size"] = m.group(1).strip()

    # üåê Open: http://...  line written by create.sh
    m = _re.search(r"Open:\s+(https?://\S+)", log_text)
    if m: stats["site_url"] = m.group(1).strip()

    return stats


def step_build_log(site_slug: str):
    """
    Fetch and parse build.log.

    Remote: nginx serves it statically at REMOTE_SITE_URL/<slug>/build.log
    Local : read directly from SITES_DIR/<slug>/build.log
    """
    print(f"\n{YELLOW}[Step 4.5] Build log & stats{NC}")

    log_text: str = ""

    if REMOTE:
        log_url = f"{REMOTE_SITE_URL}/{site_slug}/build.log"
        info(f"Fetching: {log_url}")
        try:
            r = httpx.get(log_url, timeout=10)
            if r.status_code == 200:
                log_text = r.text
                ok(f"build.log fetched ({len(log_text):,} bytes)")
            else:
                warn(f"build.log returned HTTP {r.status_code}")
                skip("Build log (not available yet)")
                return
        except Exception as e:
            warn(f"Could not fetch build.log: {e}")
            skip("Build log (fetch error)")
            return
    else:
        log_path = SITES_DIR / site_slug / "build.log"
        info(f"Reading: {log_path}")
        if not log_path.exists():
            warn("build.log not found on disk")
            skip("Build log (file missing)")
            return
        log_text = log_path.read_text(errors="replace")
        ok(f"build.log read ({len(log_text):,} bytes)")

    # Detect build state from tail of log
    tail = log_text[-2000:]
    if "üåê Open:" in tail:
        build_status, sc = "COMPLETE", GREEN
    elif "‚ùå Failed" in tail or "exit 1" in tail:
        build_status, sc = "FAILED",   RED
    else:
        build_status, sc = "IN PROGRESS", YELLOW

    print()
    print(f"  {BOLD}Build status:{NC} {sc}{build_status}{NC}")
    print()

    stats = _parse_build_stats(log_text)
    if stats:
        print(f"  {CYAN}{'‚îÄ'*50}{NC}")
        print(f"  {BOLD}  üìä Build Stats{NC}")
        print(f"  {CYAN}{'‚îÄ'*50}{NC}")
        if "total_time"         in stats: print(f"    ‚è±Ô∏è  Time       : {stats['total_time']}")
        if "mode"               in stats: print(f"    üèóÔ∏è  Mode       : {stats['mode']}")
        if "images_generated"   in stats:
            imgs_ok   = stats.get("images_generated", 0)
            imgs_tot  = stats.get("images_total", 0)
            imgs_fail = stats.get("images_failed", 0)
            print(f"    üñºÔ∏è  Images     : {imgs_ok}/{imgs_tot} generated"
                  + (f"  {RED}({imgs_fail} failed){NC}" if imgs_fail else f"  {GREEN}‚úì{NC}"))
        if "assets_size"        in stats: print(f"    üì¶ Assets     : {stats['assets_size']}")
        if "total_size"         in stats: print(f"    üìÅ Total size : {stats['total_size']}")
        if "estimated_cost_usd" in stats: print(f"    üí∞ Est. cost  : ${stats['estimated_cost_usd']:.3f}")
        if "site_url"           in stats: print(f"    üåê Live URL   : {BOLD}{stats['site_url']}{NC}")
        print(f"  {CYAN}{'‚îÄ'*50}{NC}")
        print()
        ok("Build stats parsed successfully")
    else:
        warn("Could not parse stats from log (build may still be in progress)")
        skip("Stats parse")




def step_validate_local(site_dir: Path):
    print(f"\n{YELLOW}[Step 5] Validate output & open with Playwright (LOCAL){NC}")

    # File checks
    required_files = [
        site_dir / "index.html",
        site_dir / "style.css",
        site_dir / "assets" / "hero.png",
        site_dir / "assets" / "gallery-1.png",
        site_dir / "assets" / "gallery-2.png",
        site_dir / "assets" / "workshop.png",
        site_dir / "assets" / "detail.png",
        site_dir / "assets" / "process.png",
    ]

    print("  File checks:")
    all_files_ok = True
    for f in required_files:
        rel = f.relative_to(site_dir)
        if f.exists() and f.stat().st_size > 0:
            size = f.stat().st_size
            print(f"    {GREEN}‚úì{NC}  {rel}  {DIM}({size:,} bytes){NC}")
        else:
            print(f"    {RED}‚úó{NC}  {rel}  {RED}MISSING or EMPTY{NC}")
            all_files_ok = False

    if all_files_ok:
        ok("All required files present and non-empty")
    else:
        fail("Some required files are missing or empty")

    print()

    # Playwright validation (local file://)
    print("  Playwright checks:")
    _playwright_validate_local(site_dir)


def _playwright_validate_local(site_dir: Path):
    try:
        from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout
    except ImportError:
        warn("playwright not installed ‚Äî skipping browser validation")
        warn("Install: pip install playwright && playwright install chromium")
        return

    index_html = site_dir / "index.html"
    screenshot  = site_dir / "test-screenshot.png"

    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-setuid-sandbox"],
        )
        page = browser.new_page(viewport={"width": 1280, "height": 900})

        try:
            page.goto(f"file://{index_html.resolve()}", wait_until="networkidle", timeout=15000)
        except PWTimeout:
            warn("Page load timed out ‚Äî taking screenshot anyway")
        except Exception as e:
            fail(f"Playwright could not open page: {e}")
            browser.close()
            return

        _playwright_dom_checks(page, screenshot)
        browser.close()


# ‚îÄ‚îÄ‚îÄ Step 5b: REMOTE ‚Äî Validate via HTTP + Playwright (http://) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def step_validate_remote(site_slug: str):
    print(f"\n{YELLOW}[Step 5] Validate output (REMOTE ‚Äî HTTP checks){NC}")
    info("Local file checks are SKIPPED in remote mode.")
    skip("Local file existence checks (not accessible from this machine)")
    skip("Local build.log tailing (not accessible from this machine)")

    # Primary URL: REMOTE_SITE_URL/<slug>/index.html
    # e.g. http://192.168.0.114/parrucchiere-la-spezia/index.html
    primary_url = f"{REMOTE_SITE_URL}/{site_slug}/index.html"

    # Fallback candidates if primary doesn't respond with 200
    fallback_candidates = [
        f"{REMOTE_SITE_URL}/{site_slug}/",
        f"{REMOTE_SITE_URL}/sites/{site_slug}/index.html",
        f"{REMOTE_SITE_URL}/sites/{site_slug}/",
    ]

    site_url = None
    print()
    info(f"Primary site URL : {primary_url}")
    info(f"(override with --remote-url or REMOTE_SITE_URL env)")
    print()

    # Try primary first
    try:
        r = httpx.get(primary_url, timeout=8)
        if r.status_code == 200:
            site_url = primary_url
            ok(f"Site reachable at {primary_url}")
        else:
            warn(f"Primary URL returned HTTP {r.status_code} ‚Äî trying fallbacks...")
    except Exception as e:
        warn(f"Primary URL error: {e} ‚Äî trying fallbacks...")

    # Fallbacks
    if not site_url:
        for url in fallback_candidates:
            try:
                r = httpx.get(url, timeout=5)
                if r.status_code == 200 and "html" in r.headers.get("content-type", "").lower():
                    site_url = url
                    ok(f"Site reachable (fallback) at {url}")
                    break
                else:
                    info(f"  {url} ‚Üí HTTP {r.status_code}")
            except Exception as e:
                info(f"  {url} ‚Üí error: {e}")

    if site_url:
        print()
        print("  Playwright checks (HTTP remote):")
        _playwright_validate_remote(site_url, site_slug)
    else:
        fail(f"Could not reach site at {primary_url} or any fallback.")
        warn(f"Tip: use --remote-url to set the correct web server base URL")
        warn(f"     e.g.  --remote-url http://192.168.0.114")
        skip("Playwright remote check (no reachable URL found)")


def _playwright_validate_remote(site_url: str, site_slug: str):
    try:
        from playwright.sync_api import sync_playwright, TimeoutError as PWTimeout
    except ImportError:
        warn("playwright not installed ‚Äî skipping browser validation")
        warn("Install: pip install playwright && playwright install chromium")
        return

    screenshot_path = TESTS_DIR / f"remote-screenshot-{site_slug}.png"

    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=True,
            args=["--no-sandbox", "--disable-setuid-sandbox"],
        )
        page = browser.new_page(viewport={"width": 1280, "height": 900})

        try:
            page.goto(site_url, wait_until="networkidle", timeout=20000)
        except PWTimeout:
            warn("Page load timed out ‚Äî taking screenshot anyway")
        except Exception as e:
            fail(f"Playwright could not open remote page: {e}")
            browser.close()
            return

        _playwright_dom_checks(page, screenshot_path)
        browser.close()


def _playwright_dom_checks(page, screenshot: Path):
    """Shared DOM checks for both local and remote Playwright validation."""
    page.screenshot(path=str(screenshot), full_page=True)
    ok(f"Screenshot saved ‚Üí {screenshot}")

    title = page.title()
    if title:
        ok(f"Page has <title>: \"{title}\"")
    else:
        fail("Page has no <title>")

    h1_count = page.locator("h1").count()
    if h1_count >= 1:
        h1_text = page.locator("h1").first.inner_text()
        ok(f"Found <h1>: \"{h1_text[:60]}\"")
    else:
        fail("No <h1> found on page")

    imgs = page.locator("img").all()
    broken = 0
    for img in imgs:
        natural_w = img.evaluate("el => el.naturalWidth")
        if natural_w == 0:
            broken += 1
    if broken == 0:
        ok(f"All {len(imgs)} images loaded successfully (naturalWidth > 0)")
    else:
        fail(f"{broken}/{len(imgs)} images are broken (naturalWidth=0)")

    nav = page.locator("nav, header").count()
    if nav > 0:
        ok("Navigation/header element found")
    else:
        warn("No <nav> or <header> found ‚Äî may be styled differently")

    body_text = page.locator("body").inner_text().lower()
    if any(kw in body_text for kw in ["contatt", "contact", "telefon", "phone"]):
        ok("Contact information section detected")
    else:
        warn("No contact keywords found in body text")


# ‚îÄ‚îÄ‚îÄ Main ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def main():
    print()
    print(f"{BOLD}{CYAN}üß™ Review Site Factory ‚Äî Full Integration Test{NC}")
    print(f"   API     : {BASE_URL}")
    print(f"   Query   : {QUERY}")
    print(f"   Mode    : DEV (forced ‚Äî cheap images for testing)")
    if REMOTE:
        print(f"   Remote  : {BOLD}{YELLOW}ON{NC} ‚Äî local filesystem steps will be SKIPPED")
        print(f"   Site URL: {REMOTE_SITE_URL}/<slug>/index.html")
    else:
        print(f"   Remote  : OFF ‚Äî running full local test")
        print(f"   Sites   : {SITES_DIR}")
    sep()

    # Step 1: Health (always runs)
    step_health()
    sep()

    # Step 2: Scrape (always runs ‚Äî it's just an API call)
    biz = step_scrape()
    sep()

    # Step 3: Trigger build (always runs ‚Äî it's just an API call)
    site_slug = step_generate(biz)
    sep()

    # Step 4: Wait for build
    if REMOTE:
        step_wait_remote(site_slug)
    else:
        site_dir = step_wait_local(site_slug)
    sep()

    # Step 4.5: Fetch build log & stats from API (both modes)
    step_build_log(site_slug)
    sep()

    # Step 5: Validate
    if REMOTE:
        step_validate_remote(site_slug)
    else:
        step_validate_local(site_dir)
    sep()

    summary()

    if FAIL_COUNT > 0:
        sys.exit(1)

    print(f"  {GREEN}‚úÖ All checks passed!{NC}")
    if not REMOTE:
        site_dir = SITES_DIR / site_slug
        print(f"  Open the site: {BOLD}file://{(site_dir / 'index.html').resolve()}{NC}")
    else:
        print(f"  API server   : {BOLD}{BASE_URL}{NC}")
        print(f"  Live site    : {BOLD}{REMOTE_SITE_URL}/{site_slug}/index.html{NC}")
    print()


if __name__ == "__main__":
    main()
